{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "progressive-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rocky-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want my cells to look pretty automatically.\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-exercise",
   "metadata": {},
   "source": [
    "# Data source\n",
    "\n",
    "We have downloaded the January 2016 from the [New York City Taxi & Limousine Commission Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) and converted it into an Apache Parquet file using the following code:\n",
    "\n",
    "```\n",
    "df = pd.read_csv(\n",
    "    \"../data/yellow_tripdata_2016-01.csv\",\n",
    "    dtype={\"store_and_fwd_flag\": \"bool\"},\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    index_col=False,\n",
    "    infer_datetime_format=True,\n",
    "    true_values=[\"Y\"],\n",
    "    false_values=[\"N\"],\n",
    ")\n",
    "df.to_parquet(\"../data/yellow_tripdata_2016-01.parquet\")\n",
    "```\n",
    "\n",
    "This is a really [nice dataset to demonstrate a lot of things as outlined in a previous blog post](https://uwekorn.com/2019/08/22/why-the-nyc-trd-is-a-nice-training-dataset.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "removable-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/yellow_tripdata_2016-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "timely-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10906858 entries, 0 to 10906857\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  datetime64[ns]\n",
      " 3   passenger_count        int64         \n",
      " 4   trip_distance          float64       \n",
      " 5   pickup_longitude       float64       \n",
      " 6   pickup_latitude        float64       \n",
      " 7   RatecodeID             int64         \n",
      " 8   store_and_fwd_flag     bool          \n",
      " 9   dropoff_longitude      float64       \n",
      " 10  dropoff_latitude       float64       \n",
      " 11  payment_type           int64         \n",
      " 12  fare_amount            float64       \n",
      " 13  extra                  float64       \n",
      " 14  mta_tax                float64       \n",
      " 15  tip_amount             float64       \n",
      " 16  tolls_amount           float64       \n",
      " 17  improvement_surcharge  float64       \n",
      " 18  total_amount           float64       \n",
      "dtypes: bool(1), datetime64[ns](2), float64(12), int64(4)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "offshore-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 80% training and 20% test data\n",
    "df_train, df_test = train_test_split(df, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agreed-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove basic outliers from the training data\n",
    "cap_fare = df_train[\"fare_amount\"].mean() + 3 * df_train[\"fare_amount\"].std()\n",
    "cap_distance = df_train[\"trip_distance\"].mean() + 3 * df_train[\"trip_distance\"].std()\n",
    "df_train = df_train.query(\n",
    "    f\"trip_distance > 0 and trip_distance < {cap_distance} and fare_amount > 0 and fare_amount < {cap_fare}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informed-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 5% sample dataset that runs much faster\n",
    "\n",
    "df_sampled = df_train.sample(frac=0.05)\n",
    "y_sampled = df_sampled.pop(\"fare_amount\")\n",
    "y_train = df_train.pop(\"fare_amount\")\n",
    "y_test = df_test.pop(\"fare_amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-animation",
   "metadata": {},
   "source": [
    "# Simple regression baseline\n",
    "\n",
    "As we are training a regression model here and we want to be sure it performs reasonable well, we should first calculate a baseline with a very simple model.\n",
    "We then use this to benchmark all other models against it.\n",
    "\n",
    "We select the mean absolute error as our cost function as absolute dollars is a more tangible and realistic measure than square dollars. The most simple baseline for this cost function is to take the median of all values in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pregnant-miami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.11231579024577, 6.004128783019656)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_fare = y_train.median()\n",
    "(y_test - average_fare).abs().mean(), (y_train - average_fare).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-boulder",
   "metadata": {},
   "source": [
    "# Simple Feature Engineering\n",
    "\n",
    "The dataset is quite rich in features but at the start of a journey, they are realistically not all known when you start a journey. Thus we will limit ourselves to a very basic set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "engaging-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = (np.radians(x) for x in (lat1, lng1, lat2, lng2))\n",
    "    d = (\n",
    "        np.sin(lat2 / 2 - lat1 / 2) ** 2\n",
    "        + np.cos(lat1) * np.cos(lat2) * np.sin(lng2 / 2 - lng1 / 2) ** 2\n",
    "    )\n",
    "    return 2 * 6371 * np.arcsin(np.sqrt(d))  # 6,371 km is the earth radius\n",
    "\n",
    "\n",
    "column_transforms = [\n",
    "    (FunctionTransformer(), [\"passenger_count\"]),\n",
    "    (\n",
    "        FunctionTransformer(\n",
    "            func=lambda df: pd.DataFrame(\n",
    "                {\n",
    "                    \"pickup_dayofweek\": df[\"tpep_pickup_datetime\"].dt.dayofweek,\n",
    "                    \"pickup_hour\": df[\"tpep_pickup_datetime\"].dt.hour,\n",
    "                    \"pickup_minute\": df[\"tpep_pickup_datetime\"].dt.minute,\n",
    "                }\n",
    "            )\n",
    "        ),\n",
    "        [\"tpep_pickup_datetime\"],\n",
    "    ),\n",
    "    (\n",
    "        FunctionTransformer(\n",
    "            func=lambda df: pd.DataFrame(\n",
    "                {\n",
    "                    \"haversine_distance\": haversine_distance(\n",
    "                        df[\"pickup_latitude\"],\n",
    "                        df[\"pickup_longitude\"],\n",
    "                        df[\"dropoff_latitude\"],\n",
    "                        df[\"dropoff_longitude\"],\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "        ),\n",
    "        [\n",
    "            \"pickup_latitude\",\n",
    "            \"pickup_longitude\",\n",
    "            \"dropoff_latitude\",\n",
    "            \"dropoff_longitude\",\n",
    "        ],\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-genius",
   "metadata": {},
   "source": [
    "Instead of using ordinary least squares (OLS) which optimizes the L2 norm, we are taking as the first model approach the [Theil-Sen Regressor](https://scikit-learn.org/stable/auto_examples/linear_model/plot_theilsen.html). Due to its computational complexity, we only train it on 5% of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "honey-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 16 s, total: 2min 6s\n",
      "Wall time: 2min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('functiontransformer-1',\n",
       "                                                  FunctionTransformer(),\n",
       "                                                  ['passenger_count']),\n",
       "                                                 ('functiontransformer-2',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x107cd68b0>),\n",
       "                                                  ['tpep_pickup_datetime']),\n",
       "                                                 ('functiontransformer-3',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x15db98b80>),\n",
       "                                                  ['pickup_latitude',\n",
       "                                                   'pickup_longitude',\n",
       "                                                   'dropoff_latitude',\n",
       "                                                   'dropoff_longitude'])])),\n",
       "                ('theilsenregressor',\n",
       "                 TheilSenRegressor(max_subpopulation=10000))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tsr = make_pipeline(make_column_transformer(*column_transforms), TheilSenRegressor())\n",
    "tsr.fit(df_sampled, y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hundred-roads",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53.22234508455122, 84.59079127235368)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tsr.predict(df_train) - y_train).abs().mean(), (\n",
    "    tsr.predict(df_test) - y_test\n",
    ").abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-manhattan",
   "metadata": {},
   "source": [
    "As the Theil-Sen regressor sadly performs much worse than our above baseline, we use instead LightGBM with L1 as the objective function. While this introduces a new dependency, it is a well-proven technique and as the metric shows, also an effective one in this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "first-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pipeline = make_pipeline(\n",
    "    make_column_transformer(*column_transforms),\n",
    "    LGBMRegressor(objective=\"regression_l1\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "indonesian-literacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('functiontransformer-1',\n",
       "                                                  FunctionTransformer(),\n",
       "                                                  ['passenger_count']),\n",
       "                                                 ('functiontransformer-2',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x107cd68b0>),\n",
       "                                                  ['tpep_pickup_datetime']),\n",
       "                                                 ('functiontransformer-3',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x15db98b80>),\n",
       "                                                  ['pickup_latitude',\n",
       "                                                   'pickup_longitude',\n",
       "                                                   'dropoff_latitude',\n",
       "                                                   'dropoff_longitude'])])),\n",
       "                ('lgbmregressor', LGBMRegressor(objective='regression_l1'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_pipeline.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "durable-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9753373838193955"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lgbm_pipeline.predict(df_train) - y_train).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "challenging-florist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1114189266420054"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lgbm_pipeline.predict(df_test) - y_test).abs().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
